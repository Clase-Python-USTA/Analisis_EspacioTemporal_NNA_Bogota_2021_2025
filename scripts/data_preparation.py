# ============================================================
# DATA PREPARATION - Proyecto NNA Bogot√° (2021‚Äì2025)
# Limpieza, transformaci√≥n y preparaci√≥n de datos
# ============================================================

import os # Manipulaci√≥n de rutas
import pandas as pd # Manipulaci√≥n de datos
import numpy as np # C√°lculos num√©ricos
import re # Expresiones regulares
import matplotlib.pyplot as plt # Visualizaci√≥n
import seaborn as sns # Visualizaci√≥n avanzada
from datetime import datetime # Manejo de fechas
from dotenv import load_dotenv # Carga variables entorno
import warnings     # Manejo de warnings
import json # Manejo de JSON

# Configuraci√≥n del entorno
warnings.filterwarnings('ignore')
sns.set_style("whitegrid")
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 10

print("="*70)
print(" DATA PREPARATION - PROYECTO NNA BOGOT√Å (2021-2025)")
print("="*70)
print()

"""
============================================================
RESUMEN EJECUTIVO - DATA PREPARATION
Proyecto: NNA Bogot√° (2021-2025)
============================================================

 PROP√ìSITO:
    Limpia, transforma y prepara los datos para an√°lisis posterior.
    Convierte datos brutos en datos listos para modelado.

 OBJETIVO PRINCIPAL:
    Preparar una base de datos limpia, consistente y sin informaci√≥n
    personal, lista para an√°lisis espacio-temporal.

============================================================
 ESTRUCTURA DEL PROCESO (7 PASOS)
============================================================

PASO 1: CARGA DE DATOS
--------
- Detecta formato del archivo (Excel/CSV)
- Carga hoja 'BD' si existe, si no, la √∫ltima hoja
- Reporta dimensiones y memoria utilizada
- Validaci√≥n inicial del archivo

PASO 2: ESTANDARIZACI√ìN DE COLUMNAS
--------
- Limpia nombres de columnas:
  - Elimina espacios y caracteres especiales
  - Convierte todo a MAY√öSCULAS
  - Reemplaza espacios por guiones bajos (_)
  - Ejemplo: "Nombre Columna!" ‚Üí "NOMBRE_COLUMNA"
- Guarda mapeo de cambios en JSON para trazabilidad
- Elimina guiones bajos duplicados

PASO 3: ELIMINACI√ìN DE INFORMACI√ìN PERSONAL (PII)
--------
- Identifica y elimina columnas con datos personales:
  - Nombres, apellidos, documentos
  - Tel√©fonos, correos, direcciones
  - Informaci√≥n de acudientes
  - Nombres de EPS/EAPB
- EXCEPCIONES: Mantiene columnas como:
  - NUMERO_DE_MANZANA_DEL_CUIDADO
  - NUMERO_DE_FICHA_ANTERIOR
- Reporta columnas eliminadas

PASO 4: LIMPIEZA DE INCONSISTENCIAS
--------
- Limpia texto en columnas categ√≥ricas:
  - Elimina espacios extra
  - Convierte 'nan', 'None', '' a NaN real
- Estandariza fechas a formato datetime
- Elimina registros duplicados completos
- Estandariza valores categ√≥ricos:
  - 'Si', 'si', 's', '1' ‚Üí 'SI'
  - 'No', 'no', 'n', '0' ‚Üí 'NO'
  - NOTA: Mantiene '99999' como c√≥digo v√°lido del sistema

PASO 5: MANEJO DE VALORES FALTANTES
--------
- Calcula % de nulos por columna
- Genera reporte de nulos en Excel
- Identifica columnas con >90% nulos (casi vac√≠as)
- Imputa valores en categ√≥ricas (<50% nulos):
  - Rellena con 'No especificado'
- Genera gr√°fico de Top 20 variables con m√°s nulos
- NO elimina autom√°ticamente columnas vac√≠as (solo reporta)

PASO 6: AN√ÅLISIS EXPLORATORIO INICIAL (EDA)
--------
- Estad√≠sticas descriptivas de variables num√©ricas:
  - Media, mediana, desviaci√≥n est√°ndar, etc.
  - Exporta a Excel
- Distribuciones de variables categ√≥ricas:
  - Gr√°ficos de barras para primeras 10 variables
  - Solo si tienen <50 categor√≠as √∫nicas
- An√°lisis temporal:
  - Si existe columna A√ëO o FECHA_INTERVENCION
  - Genera gr√°fico de distribuci√≥n anual
  - Crea columna A√ëO si no existe

PASO 7: EXPORTACI√ìN DE BASE FINAL
--------
- Exporta datos limpios a:
  - Excel: base_nna_limpia.xlsx
  - CSV: base_nna_limpia.csv (con UTF-8-BOM)
- Genera resumen final en JSON con:
  - Fecha de procesamiento
  - Dimensiones finales (filas √ó columnas)
  - Tama√±o en MB
  - Nombre del archivo
- Guarda log completo del proceso

============================================================
 ARCHIVOS DE SALIDA
============================================================

 data/processed/
‚îú‚îÄ‚îÄ base_nna_limpia.xlsx          #  Base principal limpia (Excel)
‚îî‚îÄ‚îÄ base_nna_limpia.csv           # Base limpia en CSV

 reports/preparation/
‚îú‚îÄ‚îÄ preparation_log.txt           # Log detallado del proceso
‚îú‚îÄ‚îÄ mapeo_columnas.json           # Mapeo de nombres originales ‚Üí limpios
‚îú‚îÄ‚îÄ reporte_nulos.xlsx            # An√°lisis de valores faltantes
‚îú‚îÄ‚îÄ estadisticas_descriptivas.xlsx # Stats de variables num√©ricas
‚îî‚îÄ‚îÄ resumen_final.json            # Resumen ejecutivo

 reports/preparation/figures/
‚îú‚îÄ‚îÄ valores_faltantes.png         # Top 20 variables con nulos
‚îú‚îÄ‚îÄ distribucion_anual.png        # Intervenciones por a√±o
‚îî‚îÄ‚îÄ dist_*.png                    # Distribuciones de categ√≥ricas

============================================================
 DECISIONES CLAVE DE LIMPIEZA
============================================================
 SE MANTIENEN:
- C√≥digos '99999' (son parte del sistema, NO son missing)
- Columnas NUMERO_DE_MANZANA, NUMERO_DE_FICHA
- Todas las columnas con <90% de nulos

 SE ELIMINAN:
- Informaci√≥n personal: nombres, tel√©fonos, correos, direcciones
- Duplicados completos (filas id√©nticas)
- Caracteres especiales en nombres de columnas

 SE TRANSFORMAN:
- Fechas ‚Üí datetime
- Texto ‚Üí limpio sin espacios extra
- Categor√≠as ‚Üí estandarizadas (SI/NO/99999)
- Columnas ‚Üí MAY√öSCULAS con guiones bajos

============================================================
 CONFIGURACI√ìN
============================================================

Variables de entorno (.env):
- DATA_FILE: Ruta del archivo de datos original

Librer√≠as requeridas:
- pandas, numpy: Manipulaci√≥n de datos
- matplotlib, seaborn: Visualizaci√≥n
- python-dotenv: Variables de entorno
- openpyxl: Lectura/escritura Excel

============================================================
 RESULTADO FINAL
============================================================

Se obtiene una base de datos:
‚úì Sin informaci√≥n personal (RGPD compliant)
‚úì Con columnas estandarizadas
‚úì Sin duplicados
‚úì Con fechas en formato correcto
‚úì Con categor√≠as estandarizadas
‚úì Lista para an√°lisis espacio-temporal

La base limpia queda en:
 data/processed/base_nna_limpia.xlsx

============================================================
"""



# ============================================================
# CONFIGURACI√ìN DE RUTAS
# ============================================================

load_dotenv()

BASE_DIR = os.path.dirname(os.path.dirname(__file__))
DATA_FILE = os.getenv("DATA_FILE")

if not DATA_FILE:
    raise ValueError(" No se encontr√≥ la variable DATA_FILE en el archivo .env")

file_path = os.path.join(BASE_DIR, DATA_FILE)

# Carpetas de salida
PROCESSED_DIR = os.path.join(BASE_DIR, "data", "processed") 
PREP_REPORTS_DIR = os.path.join(BASE_DIR, "reports", "preparation") 
PREP_FIGURES_DIR = os.path.join(PREP_REPORTS_DIR, "figures") 
CLEANED_DATA_FILE = os.path.join(PROCESSED_DIR, "base_nna_limpia.xlsx") 
PREP_LOG_FILE = os.path.join(PREP_REPORTS_DIR, "preparation_log.txt") #

for path in [PROCESSED_DIR, PREP_REPORTS_DIR, PREP_FIGURES_DIR]:
    os.makedirs(path, exist_ok=True)#

# Iniciar log
log_entries = []

def log(message):
    """Registra mensaje en consola y en log"""
    print(message)
    log_entries.append(f"[{datetime.now().strftime('%H:%M:%S')}] {message}")


# ============================================================
# PASO 1: CONFIGURACI√ìN Y CARGA DE DATOS
# ============================================================

def paso1_cargar_datos():
    """Carga inicial de datos"""
    log("\n PASO 1: Configuraci√≥n y carga de datos")
    log("-"*70)
    
    ext = os.path.splitext(file_path)[-1].lower() # Extensi√≥n del archivo
    
    log(f" Cargando archivo: {os.path.basename(file_path)}")
    
    if ext in ['.xlsx', '.xls']:
        xls = pd.ExcelFile(file_path) #
        log(f"   Hojas disponibles: {xls.sheet_names}") 
        sheet = 'BD' if 'BD' in xls.sheet_names else xls.sheet_names[-1] 
        df = pd.read_excel(file_path, sheet_name=sheet) 
        log(f"   ‚úì Cargada hoja: {sheet}") 
    elif ext == '.csv':
        df = pd.read_csv(file_path, sep=None, engine='python', encoding='utf-8') 
        log(f"   ‚úì CSV cargado") 
    else:
        raise ValueError(" Formato no compatible") 
    
    log(f" Datos cargados: {df.shape[0]:,} filas √ó {df.shape[1]} columnas") 
    log(f"   Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB") 
    
    return df 


# ============================================================
# PASO 2: ESTANDARIZACI√ìN DE NOMBRES DE COLUMNAS
# ============================================================

def paso2_estandarizar_columnas(df): 
    """Limpia y estandariza nombres de columnas""" 
    log("\n  PASO 2: Estandarizaci√≥n de nombres de columnas") 
    log("-"*70) 
    
    original_cols = df.columns.tolist() 
    
    # Limpieza y normalizaci√≥n
    df.columns = (
        df.columns
        .str.strip()                          # Eliminar espacios
        .str.replace(r'\s+', '_', regex=True) # Espacios a guiones bajos
        .str.replace(r'[^\w_]', '', regex=True) # Eliminar caracteres especiales
        .str.upper()                          # Todo en may√∫sculas
    )
    
    # Eliminar guiones bajos duplicados
    df.columns = df.columns.str.replace(r'_+', '_', regex=True).str.strip('_') #
    
    # Mapeo de cambios
    cambios = {orig: nuevo for orig, nuevo in zip(original_cols, df.columns) if orig != nuevo} 
    
    log(f" Columnas estandarizadas: {len(df.columns)} variables")#
    log(f"   Columnas modificadas: {len(cambios)}")
    
    # Guardar mapeo
    with open(os.path.join(PREP_REPORTS_DIR, "mapeo_columnas.json"), "w", encoding="utf-8") as f:
        json.dump(cambios, f, indent=2, ensure_ascii=False) 
    
    return df


# ============================================================
# PASO 3: ELIMINACI√ìN DE INFORMACI√ìN PERSONAL (PII)
# ============================================================

def paso3_eliminar_pii(df):
    """Elimina informaci√≥n personal identificable"""
    log("\n PASO 3: Eliminaci√≥n de informaci√≥n personal (PII)")
    log("-"*70) 
    
    # Columnas con informaci√≥n personal
    pii_patterns = [
        'USUARIO', 'NOMBRE', 'APELLIDO', 'DOCUMENTO', 'CEDULA', 'IDENTIFICACION',
        'DIRECCION', 'DIRECCION', 'DOMICILIO', 'RESIDENCIA',
        'CORREO', 'EMAIL', 'MAIL',
        'TELEFONO', 'CELULAR', 'MOVIL', 'CONTACTO',
        'RESPONSABLE', 'ACUDIENTE', 'TUTOR',
        'NOMBRE_EAPB', 'EPS'
    ]
    
    # Identificar columnas PII
    cols_pii = []
    for col in df.columns:
        if any(pattern in col for pattern in pii_patterns):
            # Excepciones: columnas que contienen "NUMERO" pero no son personales
            if 'NUMERO_DE_MANZANA' in col or 'NUMERO_DE_FICHA' in col:
                continue
            cols_pii.append(col)
    
    # Eliminar columnas PII
    if cols_pii:
        df = df.drop(columns=cols_pii)
        log(f" Columnas PII eliminadas: {len(cols_pii)}")
        for col in cols_pii:
            log(f"   ‚Ä¢ {col}")
    else:
        log(" No se encontraron columnas PII adicionales (archivo ya anonimizado)")
    
    return df


# ============================================================
# PASO 4: LIMPIEZA DE INCONSISTENCIAS
# ============================================================

def paso4_limpiar_inconsistencias(df):
    """Limpia inconsistencias en los datos"""
    log("\n PASO 4: Limpieza de inconsistencias")
    log("-"*70)
    
    inconsistencias_corregidas = 0
    
    # 4.1 Limpiar texto en columnas categ√≥ricas
    text_cols = df.select_dtypes(include=['object']).columns
    
    for col in text_cols:
        # Eliminar espacios extra y convertir a string
        df[col] = df[col].astype(str).str.strip()
        df[col] = df[col].str.replace(r'\s+', ' ', regex=True)
        
        # Reemplazar valores como 'nan', 'None', '' por NaN real
        df[col] = df[col].replace(['nan', 'None', '', 'null', 'NULL', 'NA'], np.nan)
    
    log(f"   ‚úì Texto limpiado en {len(text_cols)} columnas")
    
    # 4.2 Estandarizar fechas
    date_cols = [c for c in df.columns if 'FECHA' in c]
    for col in date_cols:
        if df[col].dtype != 'datetime64[ns]':
            try:
                df[col] = pd.to_datetime(df[col], errors='coerce')
                log(f"   ‚úì Fecha estandarizada: {col}")
            except:
                log(f"     No se pudo convertir: {col}")
    
    # 4.3 Eliminar duplicados completos
    duplicados_antes = df.duplicated().sum()
    if duplicados_antes > 0:
        df = df.drop_duplicates()
        log(f"   ‚úì Duplicados eliminados: {duplicados_antes}")
    else:
        log(f"   ‚úì No se encontraron duplicados completos")
    
    # 4.4 Estandarizar categor√≠as comunes
    categorias_estandar = {
        'SI': ['Si', 'si', 'SI', 's√≠', 'S√≠', 's', 'S', '1', 1],
        'NO': ['No', 'no', 'NO', 'n', 'N', '0', 0],
        '99999': ['99999', '99.999', 'No aplica', 'NO APLICA', 'N/A', 'NA']
    }
    
    for col in text_cols:
        if df[col].nunique() < 20:  # Solo para columnas con pocas categor√≠as
            for estandar, variantes in categorias_estandar.items():
                df[col] = df[col].replace(variantes, estandar)
    
    log(f" Limpieza de inconsistencias completada")
    
    return df


# ============================================================
# PASO 5: MANEJO DE VALORES FALTANTES
# ============================================================

def paso5_manejar_faltantes(df):
    """Analiza y maneja valores faltantes"""
    log("\n‚öôÔ∏è  PASO 5: Manejo de valores faltantes")
    log("-"*70)
    
    # Calcular porcentaje de nulos por columna
    nulos = df.isnull().sum()
    pct_nulos = (nulos / len(df) * 100).round(2)
    
    reporte_nulos = pd.DataFrame({
        'Variable': df.columns,
        'Nulos': nulos.values,
        'Porcentaje': pct_nulos.values
    }).sort_values('Porcentaje', ascending=False)
    
    reporte_nulos.to_excel(os.path.join(PREP_REPORTS_DIR, "reporte_nulos.xlsx"), index=False)
    
    # Columnas con muchos nulos (>90%)
    cols_muy_nulas = reporte_nulos[reporte_nulos['Porcentaje'] > 90]['Variable'].tolist()
    
    if cols_muy_nulas:
        log(f"     Columnas con >90% nulos: {len(cols_muy_nulas)}")
        log(f"   Considerar eliminar: {', '.join(cols_muy_nulas[:5])}...")
        
        # Opcional: eliminar columnas casi vac√≠as
        # df = df.drop(columns=cols_muy_nulas)
        # log(f"   ‚úì Eliminadas {len(cols_muy_nulas)} columnas casi vac√≠as")
    
    # Imputaci√≥n de valores para columnas clave
    # Ejemplo: rellenar categ√≥ricas con "No especificado"
    cat_cols = df.select_dtypes(include=['object']).columns
    for col in cat_cols:
        if df[col].isnull().sum() > 0 and df[col].isnull().sum() / len(df) < 0.5:
            df[col] = df[col].fillna('No especificado')
    
    # Gr√°fico de valores faltantes
    top_nulos = reporte_nulos.head(20)
    if top_nulos['Porcentaje'].max() > 0:
        plt.figure(figsize=(10, 8))
        plt.barh(top_nulos['Variable'], top_nulos['Porcentaje'], color='coral')
        plt.xlabel('Porcentaje de valores faltantes (%)')
        plt.title('Top 20 variables con mayor porcentaje de valores faltantes')
        plt.tight_layout()
        plt.savefig(os.path.join(PREP_FIGURES_DIR, "valores_faltantes.png"), dpi=150)
        plt.close()
        log(f"   ‚úì Gr√°fico de valores faltantes guardado")
    
    log(f" An√°lisis de valores faltantes completado")
    log(f"   Promedio general de nulos: {pct_nulos.mean():.2f}%")
    
    return df


# ============================================================
# PASO 6: AN√ÅLISIS EXPLORATORIO INICIAL (EDA)
# ============================================================

def paso6_eda_inicial(df):
    """An√°lisis exploratorio de datos limpiados"""
    log("\n PASO 6: An√°lisis exploratorio inicial (EDA)")
    log("-"*70)
    
    # Resumen estad√≠stico de num√©ricas
    num_cols = df.select_dtypes(include=[np.number]).columns
    if len(num_cols) > 0:
        stats = df[num_cols].describe().T
        stats.to_excel(os.path.join(PREP_REPORTS_DIR, "estadisticas_descriptivas.xlsx"))
        log(f"   ‚úì Estad√≠sticas descriptivas guardadas ({len(num_cols)} variables num√©ricas)")
    
    # Distribuci√≥n de variables categ√≥ricas clave
    cat_cols = df.select_dtypes(include=['object']).columns[:10]  # Primeras 10
    
    for col in cat_cols:
        if df[col].nunique() < 50:  # Solo si tiene pocas categor√≠as
            freq = df[col].value_counts().head(15)
            
            plt.figure(figsize=(10, 6))
            freq.plot(kind='barh', color='steelblue')
            plt.title(f"Distribuci√≥n de {col}")
            plt.xlabel("Frecuencia")
            plt.tight_layout()
            plt.savefig(os.path.join(PREP_FIGURES_DIR, f"dist_{col}.png"), dpi=150)
            plt.close()
    
    log(f"   ‚úì Distribuciones generadas para variables categ√≥ricas")
    
    # An√°lisis temporal si existe columna de a√±o
    if 'A√ëO' in df.columns or 'FECHA_INTERVENCION' in df.columns:
        if 'A√ëO' not in df.columns and 'FECHA_INTERVENCION' in df.columns:
            df['A√ëO'] = pd.to_datetime(df['FECHA_INTERVENCION']).dt.year
        
        if 'A√ëO' in df.columns:
            dist_anual = df['A√ëO'].value_counts().sort_index()
            
            plt.figure(figsize=(10, 6))
            dist_anual.plot(kind='bar', color='mediumseagreen')
            plt.title("Distribuci√≥n de intervenciones por a√±o")
            plt.xlabel("A√±o")
            plt.ylabel("N√∫mero de intervenciones")
            plt.xticks(rotation=0)
            plt.tight_layout()
            plt.savefig(os.path.join(PREP_FIGURES_DIR, "distribucion_anual.png"), dpi=150)
            plt.close()
            log(f"   ‚úì Distribuci√≥n temporal generada")
    
    log(f" An√°lisis exploratorio inicial completado")
    
    return df


# ============================================================
# PASO 7: EXPORTACI√ìN DE BASE FINAL
# ============================================================

def paso7_exportar_datos(df):
    """Exporta base de datos limpia"""
    log("\n PASO 7: Exportaci√≥n de la base final")
    log("-"*70)
    
    # Exportar a Excel
    df.to_excel(CLEANED_DATA_FILE, index=False, engine='openpyxl')
    log(f" Base limpia exportada a: {CLEANED_DATA_FILE}")
    
    # Tambi√©n en CSV
    csv_file = CLEANED_DATA_FILE.replace('.xlsx', '.csv')
    df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    log(f" Base limpia exportada a: {csv_file}")
    
    # Generar resumen final
    resumen = {
        "fecha_procesamiento": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "filas_finales": int(df.shape[0]),
        "columnas_finales": int(df.shape[1]),
        "archivo_salida": os.path.basename(CLEANED_DATA_FILE),
        "tama√±o_mb": float((df.memory_usage(deep=True).sum() / 1024**2).round(2))
    }
    
    with open(os.path.join(PREP_REPORTS_DIR, "resumen_final.json"), "w", encoding="utf-8") as f:
        json.dump(resumen, f, indent=2, ensure_ascii=False)
    
    log(f" Resumen final generado")
    
    return df


# ============================================================
# FUNCI√ìN PRINCIPAL
# ============================================================

def main():
    """Ejecuta todo el proceso de preparaci√≥n"""
    inicio = datetime.now()
    
    try:
        # Ejecutar pasos
        df = paso1_cargar_datos()
        df = paso2_estandarizar_columnas(df)
        df = paso3_eliminar_pii(df)
        df = paso4_limpiar_inconsistencias(df)
        df = paso5_manejar_faltantes(df)
        df = paso6_eda_inicial(df)
        df = paso7_exportar_datos(df)
        
        # Resumen final
        duracion = (datetime.now() - inicio).total_seconds() 
        
        log("\n" + "="*70)
        log(" DATA PREPARATION COMPLETADO CON √âXITO")
        log("="*70)
        log(f"\n Resumen final:")
        log(f"   ‚Ä¢ Filas en base limpia: {df.shape[0]:,}")
        log(f"   ‚Ä¢ Columnas en base limpia: {df.shape[1]}")
        log(f"   ‚Ä¢ Tiempo de ejecuci√≥n: {duracion:.2f} segundos")
        log(f"\n Archivos generados:")
        log(f"   ‚Ä¢ Base limpia: {CLEANED_DATA_FILE}")
        log(f"   ‚Ä¢ Reportes: {PREP_REPORTS_DIR}")
        log(f"   ‚Ä¢ Figuras: {PREP_FIGURES_DIR}")
        log("\n" + "="*70)
        
    except Exception as e:
        log(f"\n ERROR: {str(e)}") 
        import traceback
        traceback.print_exc()
    
    finally:
        # Guardar log
        with open(PREP_LOG_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(log_entries))
        log(f"\nüìÑ Log guardado en: {PREP_LOG_FILE}") 


if __name__ == "__main__":
    main()

# ============================================================
# FIN DEL SCRIPT
# ============================================================