"""
============================================================
SCRIPT DE CONFIGURACI√ìN AUTOM√ÅTICA
Proyecto: An√°lisis NNA Bogot√° (2021-2025)
============================================================

Este script crea autom√°ticamente toda la estructura del proyecto:
- Carpetas necesarias
- Archivos de configuraci√≥n
- Scripts principales
- Documentaci√≥n

EJECUCI√ìN:
    python setup_proyecto.py

============================================================
"""

import os
import sys

def crear_estructura_carpetas():
    """Crea la estructura de carpetas del proyecto"""
    carpetas = [
        'scripts',
        'data/raw',
        'reports',
        'reports/tables',
        'reports/figures',
        'reports/figures/temporal',
        'reports/figures/spatial',
        'reports/figures/exploratory'
    ]
    
    print("üìÅ Creando estructura de carpetas...")
    for carpeta in carpetas:
        os.makedirs(carpeta, exist_ok=True)
        print(f"   ‚úì {carpeta}")
    print()


def crear_env():
    """Crea el archivo .env"""
    contenido = """# ============================================================
# ARCHIVO DE CONFIGURACI√ìN - Proyecto NNA Bogot√°
# ============================================================

# Ruta al archivo de datos (puede ser .xlsx, .xls o .csv)
# IMPORTANTE: Actualiza esta ruta con la ubicaci√≥n real de tu archivo

# Opci√≥n 1: Ruta relativa (recomendada)
DATA_FILE=data/raw/base_datos_completa_NNA_TI_anon.xlsx

# Opci√≥n 2: Ruta absoluta (descomenta si la relativa no funciona)
# DATA_FILE=C:/Users/ASUS/OneDrive - Universidad Santo Tom√°s/SANTO TOMAS/8-SEMESTRE/PYTHON/Analisis_EspacioTemporal_NNA_Bogota_2021_2025/data/raw/base_datos_completa_NNA_TI_anon.xlsx

# ============================================================
"""
    
    with open('.env', 'w', encoding='utf-8') as f:
        f.write(contenido)
    
    print("‚úÖ Archivo .env creado")


def crear_requirements():
    """Crea el archivo requirements.txt"""
    contenido = """# ============================================================
# DEPENDENCIAS - Proyecto NNA Bogot√°
# ============================================================
#
# INSTALACI√ìN:
# pip install -r requirements.txt
#
# ============================================================

# Manejo de datos
pandas==2.1.4
numpy==1.26.2
openpyxl==3.1.2

# Visualizaciones
matplotlib==3.8.2
seaborn==0.13.0

# Variables de entorno
python-dotenv==1.0.0

# Opcional: Para an√°lisis adicionales
scipy==1.11.4
scikit-learn==1.3.2
"""
    
    with open('requirements.txt', 'w', encoding='utf-8') as f:
        f.write(contenido)
    
    print("‚úÖ Archivo requirements.txt creado")


def crear_gitignore():
    """Crea el archivo .gitignore"""
    contenido = """# ============================================================
# .gitignore - Proyecto NNA Bogot√°
# ============================================================

# Archivos de configuraci√≥n sensibles
.env

# Datos (no subir datos reales)
data/raw/*.xlsx
data/raw/*.xls
data/raw/*.csv
data/processed/

# Reportes generados
reports/

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
ENV/

# Jupyter Notebook
.ipynb_checkpoints

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# Sistema operativo
.DS_Store
Thumbs.db
"""
    
    with open('.gitignore', 'w', encoding='utf-8') as f:
        f.write(contenido)
    
    print("‚úÖ Archivo .gitignore creado")


def crear_readme():
    """Crea el archivo README.md"""
    contenido = """# üìä Data Understanding - Proyecto NNA Bogot√° (2021-2025)

An√°lisis exploratorio completo de intervenciones con Ni√±os, Ni√±as y Adolescentes en Bogot√°, incluyendo an√°lisis espacio-temporal y de contexto social.

## üéØ Caracter√≠sticas principales

- ‚úÖ **Carga autom√°tica** de archivos Excel (.xlsx, .xls) o CSV
- üßπ **Limpieza y normalizaci√≥n** de columnas
- üîí **Anonimizaci√≥n** de datos sensibles
- üìñ **Diccionario de datos** completo y autom√°tico
- üîç **An√°lisis exploratorio exhaustivo** de todas las variables
- üìà **An√°lisis espacio-temporal** con detecci√≥n de tendencias
- üíä **An√°lisis de r√©gimen de salud** y contexto social
- üó∫Ô∏è **Identificaci√≥n de zonas de alerta** por cambios significativos
- üìä **Visualizaciones autom√°ticas** (gr√°ficos, mapas de calor, correlaciones)
- üìù **Reportes en m√∫ltiples formatos** (Excel, CSV, JSON, Markdown)

---

## üöÄ Instalaci√≥n r√°pida

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Configurar archivo .env (editar con tu ruta de datos)
# Abrir .env y actualizar DATA_FILE

# 3. Ejecutar an√°lisis
python scripts/data_understanding.py
```

---

## üìÇ Estructura del proyecto

```
Analisis_EspacioTemporal_NNA_Bogota_2021_2025/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/                           # Tus archivos de datos
‚îÇ       ‚îî‚îÄ‚îÄ base_datos_completa_NNA_TI_anon.xlsx
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ data_understanding.py          # Script principal
‚îÇ
‚îú‚îÄ‚îÄ reports/                           # Se genera autom√°ticamente
‚îÇ   ‚îú‚îÄ‚îÄ data_summary.md                # Reporte principal
‚îÇ   ‚îú‚îÄ‚îÄ tables/                        # Tablas generadas
‚îÇ   ‚îî‚îÄ‚îÄ figures/                       # Gr√°ficos generados
‚îÇ       ‚îú‚îÄ‚îÄ temporal/
‚îÇ       ‚îú‚îÄ‚îÄ spatial/
‚îÇ       ‚îî‚îÄ‚îÄ exploratory/
‚îÇ
‚îú‚îÄ‚îÄ .env                               # Configuraci√≥n (EDITAR)
‚îú‚îÄ‚îÄ .gitignore                         # Archivos ignorados por Git
‚îú‚îÄ‚îÄ requirements.txt                   # Dependencias
‚îî‚îÄ‚îÄ README.md                          # Este archivo
```

---

## ‚ñ∂Ô∏è Uso detallado

### Configuraci√≥n inicial

1. **Edita el archivo `.env`** y actualiza la ruta de tu archivo de datos:
   ```bash
   DATA_FILE=data/raw/tu_archivo.xlsx
   ```

2. **Instala las dependencias**:
   ```bash
   pip install -r requirements.txt
   ```

### Ejecuci√≥n

**Desde la terminal:**
```bash
python scripts/data_understanding.py
```

**Desde VS Code:**
1. Abre `scripts/data_understanding.py`
2. Presiona `F5` o click en Run ‚ñ∂Ô∏è

---

## üìä Resultados generados

### Tablas (Excel/CSV)
- `diccionario_datos.xlsx` - Descripci√≥n completa de variables
- `distribucion_localidad_a√±o.csv` - Datos espacio-temporales
- `tendencias_por_localidad.xlsx` - An√°lisis de cambios
- `zonas_alerta.csv` - Localidades con cambios significativos
- `regimen_por_localidad_porcentaje.xlsx` - Distribuci√≥n de afiliaci√≥n
- Y m√°s...

### Visualizaciones (PNG)
- Evoluci√≥n temporal de intervenciones
- Mapas de calor localidad √ó a√±o
- Distribuci√≥n por r√©gimen de salud
- Matrices de correlaci√≥n
- Histogramas y gr√°ficos de barras
- Y m√°s...

### Reporte
- `data_summary.md` - Documento Markdown con resumen completo

---

## üéØ Objetivos del an√°lisis

1. **Describir** la distribuci√≥n de intervenciones por localidad y a√±o
2. **Identificar** localidades con aumentos o disminuciones significativas
3. **Relacionar** cambios con el tipo de afiliaci√≥n en salud

---

## ‚ö†Ô∏è Soluci√≥n de problemas

### Error: "No se encontr√≥ DATA_FILE"
- Verifica que existe el archivo `.env`
- Aseg√∫rate de que `DATA_FILE` tenga la ruta correcta

### Error: "No se encontr√≥ el archivo"
- Verifica la ruta en `.env`
- Prueba con ruta absoluta si la relativa no funciona

### Error: "ModuleNotFoundError"
- Ejecuta: `pip install -r requirements.txt`

---

## üìù Notas importantes

- ‚ö†Ô∏è **Privacidad**: El script anonimiza autom√°ticamente datos sensibles
- ‚è±Ô∏è **Tiempo**: Archivos grandes pueden tardar varios minutos
- üíæ **Espacio**: Reserva ~500MB para reportes y figuras

---

## üìß Contacto

Para dudas o problemas, revisar la documentaci√≥n en el c√≥digo fuente.

---

**Metodolog√≠a**: CRISP-DM (Cross-Industry Standard Process for Data Mining)
**√öltima actualizaci√≥n**: Octubre 2025
"""
    
    with open('README.md', 'w', encoding='utf-8') as f:
        f.write(contenido)
    
    print("‚úÖ Archivo README.md creado")


def crear_data_understanding():
    """Crea el script principal data_understanding.py"""
    # Aqu√≠ va el c√≥digo completo que ya creamos
    contenido = '''# ============================================================
# DATA UNDERSTANDING - Proyecto NNA Bogot√° (2021‚Äì2025)
# Versi√≥n extendida con an√°lisis espacio-temporal
# ============================================================

import os
import pandas as pd
import numpy as np
import hashlib
import matplotlib.pyplot as plt
import seaborn as sns
from dotenv import load_dotenv
from datetime import datetime
import warnings
import json

warnings.filterwarnings('ignore')
sns.set_style("whitegrid")

# ============================================================
# 1. CONFIGURACI√ìN DE RUTAS
# ============================================================

load_dotenv()

BASE_DIR = os.path.dirname(os.path.dirname(__file__))
DATA_FILE = os.getenv("DATA_FILE")

if not DATA_FILE:
    raise ValueError("‚ùå No se encontr√≥ la variable DATA_FILE en el archivo .env")

file_path = os.path.join(BASE_DIR, DATA_FILE)

if not os.path.exists(file_path):
    raise FileNotFoundError(f"‚ùå No se encontr√≥ el archivo: {file_path}")

# Estructura de carpetas
REPORTS_DIR = os.path.join(BASE_DIR, "reports")
FIGURES_DIR = os.path.join(REPORTS_DIR, "figures")
TABLES_DIR = os.path.join(REPORTS_DIR, "tables")
TEMPORAL_DIR = os.path.join(FIGURES_DIR, "temporal")
SPATIAL_DIR = os.path.join(FIGURES_DIR, "spatial")
EXPLORATORY_DIR = os.path.join(FIGURES_DIR, "exploratory")
SUMMARY_FILE = os.path.join(REPORTS_DIR, "data_summary.md")
ALERT_ZONES_FILE = os.path.join(TABLES_DIR, "zonas_alerta.csv")

for path in [REPORTS_DIR, FIGURES_DIR, TABLES_DIR, TEMPORAL_DIR, SPATIAL_DIR, EXPLORATORY_DIR]:
    os.makedirs(path, exist_ok=True)

print(f"üìÅ Estructura de carpetas creada en: {REPORTS_DIR}")


# ============================================================
# 2. CARGA DE DATOS CON DETECCI√ìN AUTOM√ÅTICA
# ============================================================

def load_data(file_path):
    """Carga datos desde Excel o CSV con detecci√≥n autom√°tica"""
    ext = os.path.splitext(file_path)[-1].lower()
    
    print(f"üìÇ Cargando archivo: {os.path.basename(file_path)}")
    
    if ext in ['.xlsx', '.xls']:
        xls = pd.ExcelFile(file_path)
        print(f"   Hojas disponibles: {xls.sheet_names}")
        sheet = 'BD' if 'BD' in xls.sheet_names else xls.sheet_names[-1]
        df = pd.read_excel(file_path, sheet_name=sheet)
        print(f"   ‚úì Cargada hoja: {sheet}")
    elif ext == '.csv':
        df = pd.read_csv(file_path, sep=None, engine='python', encoding='utf-8')
        print(f"   ‚úì CSV cargado con detecci√≥n autom√°tica de separador")
    else:
        raise ValueError("‚ùå Formato no compatible. Usa .csv, .xlsx o .xls")
    
    print(f"‚úÖ Datos cargados: {df.shape[0]:,} filas √ó {df.shape[1]} columnas")
    return df


# ============================================================
# 3. LIMPIEZA Y NORMALIZACI√ìN
# ============================================================

def clean_columns(df):
    """Limpia y normaliza nombres de columnas"""
    original_cols = df.columns.tolist()
    
    df.columns = (
        df.columns
        .str.strip()
        .str.replace(' ', '_')
        .str.replace(r'[^\\w]', '', regex=True)
        .str.upper()
    )
    
    col_mapping = dict(zip(original_cols, df.columns))
    with open(os.path.join(TABLES_DIR, "column_mapping.json"), "w", encoding="utf-8") as f:
        json.dump(col_mapping, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Columnas normalizadas: {len(df.columns)} variables")
    return df


def anonymize(df):
    """Anonimiza informaci√≥n sensible"""
    sensitive_cols = [
        'USUARIO', 'NOMBRE', 'APELLIDO', 'DOCUMENTO', 'ID_USUARIO',
        'DIRECCI√ìN', 'DIRECCION', 'DIRECCI√ìN_DE_LA_VIVIENDA', 'DIRECCION_VIVIENDA',
        'CORREO', 'CORREO_1', 'CORREO_2', 'EMAIL', 'MAIL',
        'TEL√âFONO', 'TELEFONO', 'TEL√âFONO_1', 'TEL√âFONO_2', 'TELEFONO_1', 'TELEFONO_2', 'CELULAR',
        'NOMBRE_EAPB', 'NOMBRE_EAPB1', 'RESPONSABLE', 'ACUDIENTE'
    ]
    
    removed = [c for c in sensitive_cols if c in df.columns]
    df.drop(columns=removed, inplace=True, errors='ignore')
    
    id_cols = [c for c in df.columns if 'ID' in c and c not in ['ID_LOCALIDAD', 'ID_UPZ']]
    for col in id_cols:
        if df[col].dtype == 'object' or pd.api.types.is_integer_dtype(df[col]):
            df[col] = df[col].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest()[:16] if pd.notna(x) else x)
    
    print(f"‚úÖ Anonimizaci√≥n completa: {len(removed)} columnas eliminadas, {len(id_cols)} IDs encriptados")
    return df


# ============================================================
# 4. DETECCI√ìN AUTOM√ÅTICA DE VARIABLES TEMPORALES
# ============================================================

def detect_temporal_columns(df):
    """Detecta y procesa columnas de fecha/a√±o"""
    temporal_info = {}
    
    date_candidates = [c for c in df.columns if any(x in c for x in ['FECHA', 'DATE', 'A√ëO', 'ANO', 'YEAR', 'MES', 'MONTH'])]
    
    for col in date_candidates:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            temporal_info[col] = 'datetime'
        elif df[col].dtype == 'object':
            try:
                df[col] = pd.to_datetime(df[col], errors='coerce')
                temporal_info[col] = 'datetime_converted'
            except:
                pass
    
    for col in temporal_info.keys():
        if 'A√ëO' not in df.columns and 'YEAR' not in df.columns:
            df['A√ëO'] = df[col].dt.year
            print(f"   ‚úì Columna 'A√ëO' extra√≠da de {col}")
    
    year_cols = [c for c in df.columns if c in ['A√ëO', 'ANO', 'YEAR', 'ANIO']]
    if year_cols:
        df['A√ëO'] = pd.to_numeric(df[year_cols[0]], errors='coerce')
    
    if 'A√ëO' in df.columns:
        years = df['A√ëO'].dropna().unique()
        print(f"‚úÖ A√±os detectados: {sorted([int(y) for y in years if not np.isnan(y)])}")
        temporal_info['years_available'] = sorted([int(y) for y in years if not np.isnan(y)])
    else:
        print("‚ö†Ô∏è  No se detect√≥ columna de a√±o")
    
    return df, temporal_info


# [CONTIN√öA EN EL SIGUIENTE MENSAJE - El c√≥digo es muy largo]
# Por limitaciones de espacio, te mostrar√© c√≥mo crear el archivo completo...
'''
    
    print("‚ö†Ô∏è  Creando script data_understanding.py...")
    print("   Por favor, copia el c√≥digo completo del artifact 'data_understanding_nna'")
    print("   y p√©galo en: scripts/data_understanding.py")
    print()


def main():
    """Ejecuta la configuraci√≥n completa del proyecto"""
    print("="*70)
    print("üöÄ CONFIGURACI√ìN AUTOM√ÅTICA DEL PROYECTO")
    print("   An√°lisis NNA Bogot√° (2021-2025)")
    print("="*70)
    print()
    
    # Crear estructura
    crear_estructura_carpetas()
    crear_env()
    crear_requirements()
    crear_gitignore()
    crear_readme()
    
    print("="*70)
    print("‚úÖ CONFIGURACI√ìN COMPLETADA")
    print("="*70)
    print()
    print("üìã PR√ìXIMOS PASOS:")
    print()
    print("1. üìù Copia el c√≥digo del artifact 'data_understanding_nna' completo")
    print("   y p√©galo en: scripts/data_understanding.py")
    print()
    print("2. ‚öôÔ∏è  Edita el archivo .env y actualiza la ruta de tus datos:")
    print("   DATA_FILE=data/raw/tu_archivo.xlsx")
    print()
    print("3. üì¶ Instala las dependencias:")
    print("   pip install -r requirements.txt")
    print()
    print("4. ‚ñ∂Ô∏è  Ejecuta el an√°lisis:")
    print("   python scripts/data_understanding.py")
    print()
    print("="*70)
    print()
    print("üìÅ Archivos creados:")
    print("   ‚úì .env")
    print("   ‚úì .gitignore") 
    print("   ‚úì requirements.txt")
    print("   ‚úì README.md")
    print("   ‚úì Estructura de carpetas")
    print()
    print("‚ö†Ô∏è  PENDIENTE: Crear scripts/data_understanding.py")
    print("   (Copia el c√≥digo del artifact que te compart√≠)")
    print()


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        import traceback
        traceback.print_exc()